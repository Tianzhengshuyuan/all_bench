13,"Утверждение 1| F1-мера может быть особенно полезна для наборов данных с сильным дисбалансом классов. Утверждение 2| Площадь под кривой ошибок (ROC) является одной из основных метрик, используемых для оценки детекторов аномалий.","True, True","False, False","True, False","False, True",A
109,Какое из следующих утверждений неверно?,"Семантические модели сегментации предсказывают класс каждого пикселя, тогда как многоклассовые классификаторы изображений предсказывают класс целого изображения.","Прямоугольная рамка (bounding box) с IoU (отношением пересечения к объединению), равным 96%, вероятно, будет считаться истинно положительной.","Когда предсказанная прямоугольная рамка не соответствует никакому объекту на сцене, она считается ложноположительной.","Прямоугольная рамка с IoU (отношением пересечения к объединению), равным 3%, вероятно, будет считаться ложноотрицательной.",D
92,Какой из следующих методов более подходящий для выбора признаков?,Ridge,Lasso,оба (a) и (b),"ни (a), ни (b)",B
105,"Утверждение 1 | Градиент ReLU равен нулю при $x<0$, а градиент сигмоиды $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ для всех $x$. Утверждение 2 | Сигмоидная функция имеет непрерывный градиент, а ReLU имеет разрывной градиент.","Верно, Верно","Неверно, Неверно","Верно, Неверно","Неверно, Верно",A
101,"A и B — это два события. Если P(A, B) уменьшается, а P(A) увеличивается, то что из следующего является верным?",P(A|B) уменьшается,P(B|A) уменьшается,P(B) уменьшается,Все вышеперечисленное,B
16,"Утверждение 1 | В оригинальной статье ResNet используется нормализация слоя, а не нормализация по мини-пакетам. Утверждение 2 | DCGANs используют самоаттеншн для стабилизации обучения.","Верно, Верно","Неверно, Неверно","Верно, Неверно","Неверно, Верно",B
85,"Утверждение 1 | Обучающая ошибка классификатора 1-ближайшего соседа равна 0. Утверждение 2 | При увеличении числа точек данных до бесконечности оценка апостериорного максимума (MAP) приближается к оценке максимального правдоподобия (MLE) для всех возможных априорных распределений. Другими словами, при достаточном количестве данных выбор априорного распределения не играет роли.","Верно, Верно","Неверно, Неверно","Верно, Неверно","Неверно, Верно",C
95,"Утверждение 1| Для любых двух переменных x и y, имеющих совместное распределение p(x, y), всегда выполняется H[x, y] ≥ H[x] + H[y], где H — это функция энтропии. Утверждение 2| Для некоторых ориентированных графов морализация уменьшает количество ребер в графе.","Верно, Верно","Неверно, Неверно","Верно, Неверно","Неверно, Верно",B
81,"Утверждение 1 | Помимо EM, градиентный спуск может использоваться для выполнения вывода или обучения модели смеси гауссиан. Утверждение 2 | При условии фиксированного числа атрибутов, оптимальный байесовский классификатор на основе гауссиан может быть обучен за время, линейное относительно количества записей в наборе данных.","True, True","False, False","True, False","False, True",A
22,"Суждение 1 | У VGGNets свертывающие ядра имеют меньшую ширину и высоту, чем у ядер первого слоя AlexNet. Суждение 2 | Процедуры инициализации весов, зависящие от данных, были введены до нормализации пакетов.","True, True","False, False","True, False","False, True",A
