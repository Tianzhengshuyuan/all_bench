13,"陈述1：F1分数对于类别高度不平衡的数据集特别有用。  
陈述2：ROC曲线下的面积是用于评估异常检测器的主要指标之一。",正确，正确,错误，错误,正确，错误,错误，正确,A
109,以下哪一项是错误的？,语义分割模型预测每个像素的类别，而多类别图像分类器预测整个图像的类别。,一个具有96% IoU（交并比）的边界框很可能会被视为真阳性。,当一个预测的边界框在场景中不对应任何物体时，它会被视为假阳性。,一个具有3% IoU（交并比）的边界框很可能会被视为假阴性。,D
92,以下哪一项更适合进行特征选择？,Ridge,Lasso,以上两者都是,以上两者都不是,B
105,"陈述1：ReLU在x<0时梯度为零，而Sigmoid的梯度σ(x)(1-σ(x))对所有x来说都小于等于1/4。  
陈述2：Sigmoid具有连续的梯度，而ReLU的梯度是不连续的。","True, True","False, False","True, False","False, True",A
101,"A 和 B 是两个事件。如果 P(A, B) 减小，而 P(A) 增大，以下哪一项是正确的？",P(A|B) 减小,P(B|A) 减小,P(B) 减小,以上全部,B
16,"陈述1：在原始ResNet论文中使用了层归一化（Layer Normalization），而不是批归一化（Batch Normalization）。  
陈述2：DCGANs使用自注意力（self-attention）来稳定训练。","True, True","False, False","True, False","False, True",B
85,"陈述1：1-最近邻分类器的训练误差为0。  
陈述2：随着数据点数量趋于无穷大，对于所有可能的先验分布，MAP估计会趋近于MLE估计。换句话说，给定足够的数据，先验分布的选择无关紧要。",正确，正确,错误，错误,正确，错误,错误，正确,C
95,"陈述1：对于任何两个具有联合分布p(x, y)的变量x和y，我们总有H[x, y] ≥ H[x] + H[y]，其中H是熵函数。  
陈述2：对于某些有向图，道德化（moralization）会减少图中存在的边的数量。",正确，正确,错误，错误,正确，错误,错误，正确,B
81,"陈述1：除了EM算法，梯度下降也可以用于高斯混合模型的推断或学习。  
陈述2：在属性数量固定的情况下，可以在与数据集中记录数量成线性关系的时间内学习基于高斯分布的贝叶斯最优分类器。",正确，正确,错误，错误,正确，错误,错误，正确,A
22,"陈述1：VGGNets的卷积核宽度和高度都小于AlexNet的第一层卷积核。  
陈述2：在Batch Normalization之前引入了依赖数据的权重初始化方法。","True, True","False, False","True, False","False, True",A
