13,Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.,"True, True","False, False","True, False","False, True","陈述1：F1分数对于类别高度不平衡的数据集特别有用。  
陈述2：ROC曲线下的面积是用于评估异常检测器的主要指标之一。",正确，正确,错误，错误,正确，错误,错误，正确,A
109,Which of the following is false?,"Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image.",A bounding box with an IoU (intersection over union) equal to $96\%$ would likely be considered at true positive.,"When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive.",A bounding box with an IoU (intersection over union) equal to $3\%$ would likely be considered at false negative.,以下哪一项是错误的？,语义分割模型预测每个像素的类别，而多类别图像分类器预测整个图像的类别。,一个具有96% IoU（交并比）的边界框很可能会被视为真阳性。,当一个预测的边界框在场景中不对应任何物体时，它会被视为假阳性。,一个具有3% IoU（交并比）的边界框很可能会被视为假阴性。,D
92,Which of the following is more appropriate to do feature selection?,Ridge,Lasso,both (a) and (b),neither (a) nor (b),以下哪一项更适合进行特征选择？,Ridge,Lasso,以上两者都是,以上两者都不是,B
105,"Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.","True, True","False, False","True, False","False, True","陈述1：ReLU在x<0时梯度为零，而Sigmoid的梯度σ(x)(1-σ(x))对所有x来说都小于等于1/4。  
陈述2：Sigmoid具有连续的梯度，而ReLU的梯度是不连续的。","True, True","False, False","True, False","False, True",A
101,"A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?",P(A|B) decreases,P(B|A) decreases,P(B) decreases,All of above,"A 和 B 是两个事件。如果 P(A, B) 减小，而 P(A) 增大，以下哪一项是正确的？",P(A|B) 减小,P(B|A) 减小,P(B) 减小,以上全部,B
16,"Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.","True, True","False, False","True, False","False, True","陈述1：在原始ResNet论文中使用了层归一化（Layer Normalization），而不是批归一化（Batch Normalization）。  
陈述2：DCGANs使用自注意力（self-attention）来稳定训练。","True, True","False, False","True, False","False, True",B
85,"Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.","True, True","False, False","True, False","False, True","陈述1：1-最近邻分类器的训练误差为0。  
陈述2：随着数据点数量趋于无穷大，对于所有可能的先验分布，MAP估计会趋近于MLE估计。换句话说，给定足够的数据，先验分布的选择无关紧要。",正确，正确,错误，错误,正确，错误,错误，正确,C
95,"Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] ≥ H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.","True, True","False, False","True, False","False, True","陈述1：对于任何两个具有联合分布p(x, y)的变量x和y，我们总有H[x, y] ≥ H[x] + H[y]，其中H是熵函数。  
陈述2：对于某些有向图，道德化（moralization）会减少图中存在的边的数量。",正确，正确,错误，错误,正确，错误,错误，正确,B
81,"Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.","True, True","False, False","True, False","False, True","陈述1：除了EM算法，梯度下降也可以用于高斯混合模型的推断或学习。  
陈述2：在属性数量固定的情况下，可以在与数据集中记录数量成线性关系的时间内学习基于高斯分布的贝叶斯最优分类器。",正确，正确,错误，错误,正确，错误,错误，正确,A
22,Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.,"True, True","False, False","True, False","False, True","陈述1：VGGNets的卷积核宽度和高度都小于AlexNet的第一层卷积核。  
陈述2：在Batch Normalization之前引入了依赖数据的权重初始化方法。","True, True","False, False","True, False","False, True",A
