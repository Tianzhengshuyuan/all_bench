13,"Affirmation 1 | Le score F1 peut être particulièrement utile pour les ensembles de données présentant un déséquilibre élevé entre classes.  
Affirmation 2 | La surface sous la courbe ROC est l'une des principales métriques utilisées pour évaluer les détecteurs d'anomalies.","True, True","False, False","True, False","False, True",A
109,Laquelle des affirmations suivantes est fausse ?,"Les modèles de segmentation sémantique prédisent la classe de chaque pixel, tandis que les classifieurs d'images multiclasse prédisent la classe de l'image entière.",Une boîte englobante avec un IoU (intersection sur union) égal à $96\%$ serait probablement considérée comme un vrai positif.,"Lorsqu'une boîte englobante prédite ne correspond à aucun objet de la scène, elle est considérée comme un faux positif.",Une boîte englobante avec un IoU (intersection sur union) égal à $3\%$ serait probablement considérée comme un faux négatif.,D
92,Laquelle des méthodes suivantes est plus adaptée pour la sélection de caractéristiques ?,Ridge,Lasso,les deux (a) et (b),ni (a) ni (b),B
105,"Affirmation 1 | Le gradient de la ReLU est nul pour $x<0$, et le gradient de la sigmoïde $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ pour tout $x$.  
Affirmation 2 | La sigmoïde a un gradient continu et la ReLU a un gradient discontinu.","True, True","False, False","True, False","False, True",A
101,"A et B sont deux événements. Si P(A, B) diminue alors que P(A) augmente, laquelle des affirmations suivantes est vraie ?",P(A|B) diminue,P(B|A) diminue,P(B) diminue,Toutes les réponses ci-dessus,B
16,"Affirmation 1 | Le Layer Normalization est utilisé dans l'article original sur ResNet, et non le Batch Normalization.  
Affirmation 2 | Les DCGANs utilisent l'auto-attention pour stabiliser l'entraînement.","True, True","False, False","True, False","False, True",B
85,"Énoncé 1 | L'erreur d'entraînement du classifieur 1-plus-proche-voisin est de 0.  
Énoncé 2 | Lorsque le nombre de points de données tend vers l'infini, l'estimation MAP tend vers l'estimation MLE pour tous les a priori possibles. En d'autres termes, étant donné suffisamment de données, le choix de l'a priori n'a pas d'importance.","True, True","False, False","True, False","False, True",C
95,"Énoncé 1 | Pour deux variables quelconques x et y ayant une distribution conjointe p(x, y), nous avons toujours H[x, y] ≥ H[x] + H[y], où H est la fonction d'entropie.  
Énoncé 2 | Pour certains graphes orientés, la moralisation diminue le nombre d'arêtes présentes dans le graphe.","Vrai, Vrai","Faux, Faux","Vrai, Faux","Faux, Vrai",B
81,"Affirmation 1 | En plus de l'algorithme EM, la descente de gradient peut être utilisée pour effectuer de l'inférence ou de l'apprentissage sur un modèle de mélange gaussien. Affirmation 2 | En supposant un nombre fixe d'attributs, un classifieur bayésien optimal basé sur une loi gaussienne peut être appris en un temps linéaire par rapport au nombre d'enregistrements dans le jeu de données.","True, True","False, False","True, False","False, True",A
22,"Affirmation 1 | Les VGGNets ont des noyaux de convolution de largeur et de hauteur inférieures à celles des noyaux de la première couche d'AlexNet.  
Affirmation 2 | Des procédures d'initialisation des poids dépendantes des données ont été introduites avant la normalisation par lots.","True, True","False, False","True, False","False, True",A
