"In a binary classification problem, when the number of positive and negative examples in the test set is imbalanced, which of the following evaluation metrics is relatively less reasonable (assuming precision=TP/(TP+FP), recall=TP/(TP+FN))?",F-score: 2recallprecision/(recall+precision),G-mean: sqrt(precision*recall),Accuracy: (TP+TN)/all,AUC: Area under the ROC curve,C
Which of the following methods for handling overfitting in deep learning is not advisable?,Add a dropout layer,Increase the number of layers,Data augmentation,Add a regularization term,B
"Suppose we have a dataset that can be trained with 100% accuracy with the help of a decision tree of depth 6. Now consider the following two points and select the correct option based on these two points. 1. At depth 4, there will be high bias and low variance; 2. At depth 4, there will be low bias and low variance. Note: All other hyperparameters are the same, and all other factors are unaffected.",1 and 2,Only 2,None,Only 1,D
Which of the following methods cannot be used for dimensionality reduction of high-dimensional data?,LASSO,Bagging,Principal Component Analysis,Cluster Analysis,B
The difference between L1 regularization and L2 regularization in machine learning is,Using L1 results in sparse and smooth weights,Using L2 results in sparse and smooth weights,"Using L1 results in sparse weights, and using L2 results in smooth weights","Using L2 results in sparse weights, and using L1 results in smooth weights",C
Which of the following statements about Hidden Markov Models and Conditional Random Field models is incorrect?,"Hidden Markov Models can be used for tasks such as named entity recognition, word segmentation, and part-of-speech tagging",Both Hidden Markov Models are generative models,Hidden Markov Models are not probabilistic undirected graph models,Feature selection and optimization will seriously affect the results of Hidden Markov Models,B
Which of the following hyperparameters' increase might cause overfitting in a random forest?,Learning rate,Number of trees,Depth of trees,None of the above,C
Which of the following statements about the Iterative Dichotomiser 3 (ID3) algorithm is incorrect?,The ID3 algorithm is a binary tree model,"Information gain can be calculated using entropy, rather than the GINI coefficient",The ID3 algorithm requires features to be discretized,The feature with the highest information gain is selected as the root node of the tree,A
Which of the following statements about K-fold cross-validation is/are correct?,"If K=N, it is called leave-one-out cross-validation, where N is the number of samples in the validation set",A larger K value will give higher confidence in the cross-validation results compared to a smaller K value,All of the above,Increasing K will require more time to produce the cross-validation results,C
"Given m samples, perform n (n <= m) sampling. What does bootstrap data mean?",Sampling n samples without replacement from a total of N samples,Sampling m features without replacement from a total of M features,Sampling n samples with replacement from a total of N samples,Sampling m features with replacement from a total of M features,C
"If the correlation coefficient of feature vectors is used as a measure of pattern similarity, the main factors affecting the results of clustering algorithms are",Dimension,Quality of known class samples,None of the above,Classification criterion,D
"During the model training process, we generally divide the data into",Validation set,Test set,Training set,All of the above options are correct,D
"You are using logistic regression with L1 regularization for binary classification, where C is the regularization parameter, and w1 and w2 are the coefficients of x1 and x2 respectively. When you increase the value of C from 0 to a very large number, which of the following statements is correct","First w1 becomes 0, then w2 also becomes 0",w1 and w2 become 0 at the same time,"First w2 becomes 0, then w1 also becomes 0","Even after C becomes a large value, neither w1 nor w2 can become 0",D
Which of the following methods cannot be used for feature dimensionality reduction?,Deep learning SparseAutoEncoder,Matrix singular value decomposition SVD,Linear discriminant analysis,Principal component analysis,A
What probability does Bayes' theorem calculate?,Prior probability,None of the other options,Conditional probability,Joint probability,C
"In machine learning, the bias-variance decomposition is often used to explain the generalization performance of a learner. Which of the following statements is incorrect?",Variance reflects the stability of the learner's predictions,Bias reflects the accuracy of the learner's predictions,"Generalization performance is determined jointly by the capability of the learning algorithm, the sufficiency of the data, and the inherent difficulty of the learning task",Variance refers to the deviation between the expected value of the prediction and the true value,D
"Suppose you use the logistic regression algorithm to predict computer sales, and when you validate your hypothesis on a new test set, you find that the predicted values have large deviations, and your hypothesis also performs poorly on the training set. Which of the following steps should you avoid taking?",Try to decrease the regularization parameter λ,Try adding interaction features,Increase the sample size,Try using a smaller test set or fewer features,D
"Let P(w) denote the probability of the word w. Suppose we know that P(Nanjing) = 0.8, P(mayor) = 0.6, P(Jiang Daqiao) = 0.4; P(Nanjingshi) = 0.3, P(Yangtze River Bridge) = 0.5. If we assume that the occurrence of the previous and next words are independent, then the word segmentation result would be",Nanjing_mayor_Jiang Daqiao,Nanjingshi_Changlei_Daqiao,Nanjing mayor_Jiang Daqiao,Nanjingshi_Yangtze River Bridge,A
What is the difference between logistic regression and general regression analysis?,Logistic regression is designed to predict the probability of an event,Logistic regression can be used to estimate regression coefficients,All of the above,Logistic regression can be used to measure model fit,C
"Which of the following statements about ""Type-1"" and ""Type-2"" errors is incorrect",Type-1 error occurs when the hypothesis is correct but it is rejected,"Type-1 error is generally referred to as a false positive, while Type-2 error is generally referred to as a false negative",All of the above,"Type-2 error is generally referred to as a false positive, while Type-1 error is generally referred to as a false negative",D
The main factors affecting the basic K-means algorithm are,Selection of initial cluster centers,Clustering criteria,Order of sample input,Pattern similarity measure,D
Gaussian Mixture Model (GMM) is what kind of model,Unsupervised learning model,None of the other options,Semi-supervised learning model,Supervised learning model,A
The method based on grammatical rules is,Conditional Random Field,Maximum Entropy Model,Syntactic and Semantic Analysis,Maximum Entropy Hidden Markov Model,B
"There are two sample points. The first point is a positive sample with feature vector (0, -1). The second point is a negative sample with feature vector (2, 3). From the training set consisting of these two sample points, the equation of the decision boundary for constructing a linear SVM classifier is",2x-y=0,x+2y=5,x+2y=3,2x+y=4,C
"Hidden Markov Model, suppose its observation space is , and its state space is . If using the Viterbi algorithm for decoding, the time complexity will be",O(NK),O(N^2K),None of the above,O(NK^2),C
"Assuming you use an RBF kernel with a large γ value, this means:",The model will not be affected by the distance of points to the hyperplane,None of the above,The model will use only points close to the hyperplane for modeling,The model will consider using points far from the hyperplane for modeling,C
"Regarding the power spectra of ARMA (autoregressive moving average model), AR (autoregressive model), and MA (moving average model) models, which of the following statements is correct?","When the zeros of an AR model are close to the unit circle, the AR spectrum has a sharp peak",MA models are produced by the same all-pass filter,"When the poles of an MA model are close to the unit circle, the MA spectrum has a deep valley",The RMA spectrum has both sharp peaks and deep valleys,D
"Variable selection is used to choose the best subset of discriminators. If model efficiency is a concern, which of the following variable selection considerations should we NOT perform?",Cross-validation,How much the variables contribute to the model's interpretation,The information carried by the features,Multiple variables actually have the same use,B
Which of the following time series models is better suited for analyzing and forecasting volatility?,auto regressive model AR模型,autoregressive moving average model,moving average model,generalized autoregressive moving average model,D
"When we construct a linear model, we pay attention to the correlation between variables. When searching for correlation coefficients in the correlation matrix, if we find that the correlation coefficients of 3 pairs of variables (Var1 and Var2, Var2 and Var3, Var3 and Var1) are -0.98, 0.45, and 1.23 respectively, what conclusion can we draw?",All of the above,"Since Var1 and Var2 are highly correlated, we can remove one of them",Var1 and Var2 are highly correlated,A correlation coefficient of 1.23 between Var3 and Var1 is impossible,A
Which of the following methods might be used for feature selection in machine learning?,All of the above,Chi-square,Information Gain,Expected Cross Entropy,A
A major difference between LSTM and GRU is that the GRU merges which two gates of the LSTM?,forget gate and input gate,input gate and output gate,forget gate and output gate,output gate and reset gate,A
"Symbol set a, b, c, d, they are independent of each other, with corresponding probabilities 1/2, 1/4, 1/8, 1/16. The symbol containing the least information is",d,b,a,c,C
"Suppose you are using the log-loss function as the evaluation metric. Among the following options, which are correct interpretations of log-loss as an evaluation metric?",All of the above,"The lower the log-loss, the better the model","For a particular observation, if the classifier assigns a very small probability to the correct category, then the corresponding contribution to the log-loss will be very large","If a classifier is confident about incorrect predictions, log-loss will penalize it severely",A
"Given the covariance matrix P of a set of data, which of the following statements about principal components is incorrect:",Principal component analysis is the same as the K-L transform,"After principal component decomposition, the covariance matrix becomes a diagonal matrix","The optimal criterion of principal component analysis is to decompose a set of data using a set of orthogonal bases, and under the condition of selecting only the same number of components, the truncation error calculated by mean square error is the smallest",Principal components are obtained by calculating the eigenvalues of the covariance matrix,A
Which of the following statements about the attention mechanism is incorrect?,The attention mechanism assigns a weight coefficient to each element in the sequence,The attention mechanism can be used in scenarios such as machine reading comprehension and question-answering dialogue,Traditional encoder-decoder models have long-distance dependency problems,"A variant of the attention mechanism, the multi-head attention mechanism is not suitable for parallelization, as each step of computation depends on the result of the previous step",D
Which of the following is NOT a method to reduce overfitting,Collect more training data,Perform data cleaning to reduce noise,Increase the number of hidden layer nodes in the neural network,Simplify model assumptions,C
"Given three variables X, Y, Z. The Pearson correlation coefficients between (X, Y), (Y, Z), and (X, Z) are C1, C2, and C3 respectively. Now, all values of X are increased by 2 (i.e., X+2), all values of Y are decreased by 2 (i.e., Y-2), and Z remains unchanged. The correlation coefficients between (X, Y), (Y, Z), and (X, Z) after the operations are D1, D2, and D3 respectively. What is the relationship between D1, D2, D3 and C1, C2, C3?","D1 = C1, D2 < C2, D3 < C3","D1= C1, D2 < C2, D3 > C3","D1 = C1, D2 = C2, D3 = C3","D1 = C1, D2 > C2, D3 > C3",C
Which of the following statements about information gain used for splitting nodes in a decision tree is incorrect?,Information gain tends to prefer attributes with more possible values,Information gain can be calculated using entropy,Nodes with lower impurity require more information to distinguish the overall population,None of the above,C
Which of the following statements about residuals in regression analysis is correct?,The average of the residuals is always less than zero,The average of the residuals is always greater than zero,The average of the residuals is always zero,There is no such pattern for residuals,C
We build a machine learning model with 5000 features and 1 million data points. How can we effectively handle such large-scale training data?,We randomly sample some instances and train on these smaller samples,All of the above,We can use online machine learning algorithms,"We apply PCA algorithm for dimensionality reduction, reducing the number of features",B
Which of the following is not an advantage of the Conditional Random Fields (CRF) model over Hidden Markov Models (HMM) and Maximum Entropy Hidden Markov Models?,Faster speed,Can incorporate more contextual information,Globally optimal,Flexible features,A
Which of the following is not a basic method of dictionary-based Chinese word segmentation?,Maximum entropy model,Maximum probability method,Maximum matching method,Shortest path method,A
"Suppose you are using SVM to learn from data X, and some points in data X contain errors. Now, if you use a quadratic kernel function with polynomial degree 2, and use the slack variable C as one of the hyperparameters. If a small C (C approaching 0) is used, then:",Not sure,Misclassification,Correct classification,None of the above,B
Which of the following methods belongs to generative models?,Conditional Random Fields,Traditional Neural Networks,Naive Bayes,Linear Regression,C
"Under the premise that all other conditions remain unchanged, which of the following practices is more likely to cause overfitting in machine learning?",Increase the size of the training set,Remove sparse features,Use a Gaussian kernel/RBF kernel instead in the SVM algorithm,Reduce the number of nodes in the hidden layer of the neural network,C
"For the Gradient Boosting Tree algorithm, which of the following statements is correct?",Increasing the minimum number of samples required to split a node can help prevent overfitting,Reducing the number of samples used to train individual learners can reduce bias,Increasing the minimum number of samples required to split a node leads to overfitting,Increasing the number of samples used to train individual learners can reduce variance,A
"Suppose after training an SVM, you obtain a linear decision boundary and believe that the model is underfitting. When training the model in the next iteration, you should consider",Reducing the training data,Reducing the features,Computing more variables,Increasing the training data,C
Why can we process speech signals by windowing due to their what characteristic?,Random monotonicity,None of the other options,Short-time stationarity,Monotonic invariance,C
"For k-fold cross-validation, which of the following statements about k is correct?",Choosing a larger k will result in smaller bias (because the training set is closer to the entire dataset),A larger k is not necessarily better; choosing a large k increases evaluation time,"When selecting k, minimize the variance between datasets",All of the above,D
The following are characteristics of Euclidean distance:,Scale invariance,Rotation invariance,Unit-invariant property,Takes into account the distribution of patterns,B
Naive Bayes is a special type of Bayesian classifier where the feature variable is X and the class label is C. One of its assumptions is that:,The dimensions of the feature variable X are conditionally independent given the class,P(X|C) follows a Gaussian distribution,A normal distribution with mean 0 and standard deviation sqrt(2)/2,The prior probabilities P(C) of all classes are equal,A
"In an n-dimensional space, the best method to detect outliers is",Box plot,Scatter plot,Normal probability plot,Mahalanobis distance,D
"For the linear regression model, including additional variables, which of the following could be true?","R-Squared is decreasing, Adjusted R-squared is also decreasing","R-Squared is constant, Adjusted R-squared is increasing",Both R-Squared and Adjusted R-squared are increasing,None of the above,D
"Data scientists may use multiple algorithms (models) simultaneously for prediction, and finally combine the results of these algorithms to make the final prediction (ensemble learning). Which of the following statements about ensemble learning is correct?",The individual models are highly correlated,All individual models use the same algorithm,The individual models are lowly correlated,"Using ""average weights"" instead of ""voting"" in ensemble learning is better",C
"We want to train a decision tree on a large dataset, and to save time we can",Increase the learning rate,Reduce the number of trees,Increase the depth of the trees,Reduce the depth of the trees,D
"We want to reduce the number of features in the dataset, i.e., dimensionality reduction. Select the appropriate approach below:",All of the above,"We first use all the features to train a model and obtain its performance on the test set. Then we remove one feature and train again, using cross-validation to check the performance on the test set. If the performance is better than before, we can remove this feature",Use forward feature selection and backward feature elimination,Check the correlation matrix and remove some of the most highly correlated features,A
Which of the following activation functions cannot solve the problem of gradient vanishing?,Leaky-Relu,Elu,Sigmoid,Relu,C
Which of the following is not a commonly used feature selection algorithm for text classification?,Principal Component Analysis,Mutual Information,Information Gain,Chi-square statistic,A
The solving process of the Fisher linear discriminant function involves projecting the M-dimensional feature vector into ( ) for solving,One-dimensional space,Three-dimensional space,M-1 dimensional space,Two-dimensional space,A
Which of the following indicates a strong relationship between X and Y,The correlation coefficient is 0.9,None of the above,The p-value for the null hypothesis that the Beta coefficient is 0 is 0.0001,The t-statistic for the null hypothesis that the Beta coefficient is 0 is 30,A
"In the k-means algorithm, which of the following options can be used to obtain the global minimum?",All of the above,Finding the optimal number of clusters,Adjusting the number of iterations,Running the algorithm with different centroid initializations,A
"In statistical language models, the likelihood of any sentence is typically described in terms of probability, measured using maximum likelihood estimation. For some low-frequency words, no matter how much training data is expanded, their frequency of occurrence remains very low. Which of the following methods can solve this problem?",Data smoothing,N-gram grammar,Unigram grammar,Unigram segmentation,A
Which of the following statements is incorrect?,"Given n data points, if half are used for training and half for testing, the difference between training error and testing error will decrease as n increases",Boosting and bagging are both methods that combine multiple classifiers to vote; both determine the weight of individual classifiers based on their accuracy,"SVM is robust to noise (e.g., noise samples from other distributions)","In the AdaBoost algorithm, the weight update ratios for all misclassified samples are not the same",B
"A binary source X emits symbols from the set {-1,1}, and is transmitted through a discrete memoryless channel. Due to noise in the channel, the received symbols at Y are from the set {-1,1,0}. Given that P(x=-1) = 1/4, P(x=1) = 3/4, P(y=-1|x=-1) = 4/5, P(y=0|x=-1) = 1/5, P(y=1|x=1) = 3/4, P(y=0|x=1) = 1/4, find the conditional entropy H(Y|X).",0.5372,0.2375,0.5273,0.3275,B
Which of the following techniques is better for reducing the dimensionality of a dataset?,Remove columns with large data variance,Remove columns with too many missing values,Remove columns with different data trends,None of the above,B
Which of the following is not particularly suitable for dimensionality reduction of high-dimensional data,Cluster analysis,LASSO,Wavelet analysis,Laplacian eigenmap,A
What are the differences between logistic regression and multiple regression analysis?,Evaluation of regression coefficients in logistic regression,Logistic regression predicts the probability of an event occurring,Logistic regression has a better goodness of fit,All of the above,D
"The most well-known dimensionality reduction algorithms are PCA and t-SNE. Applying these two algorithms to the data ""X"" results in the datasets ""X_projected_PCA"" and ""X_projected_tSNE"". Which of the following statements about ""X_projected_PCA"" and ""X_projected_tSNE"" is correct?",Both can be explained in the nearest neighbor space,X_projected_PCA can be explained in the nearest neighbor space,Neither can be explained in the nearest neighbor space,X_projected_tSNE can be explained in the nearest neighbor space,D
Which of the following statements about the Viterbi algorithm is incorrect?,The transition probability in the Viterbi algorithm is the probability of moving from one hidden state to another hidden state,The Viterbi algorithm is a greedy algorithm,The Viterbi algorithm can be applied to Chinese word segmentation tasks,The Viterbi algorithm can obtain the globally optimal solution,B
The following ( ) does not belong to the optimal criteria for linear classifiers,Bayesian classification,Perceptron criterion function,Support Vector Machine,Fisher criterion,A
"For linear regression, which of the following assumptions should we have?",Identifying outliers is important because linear regression is sensitive to outliers,Linear regression assumes that the data has no multicollinearity,Linear regression requires all variables to be normally distributed,None of the above,D
The following is not a requirement of the data for the ID3 algorithm of decision tree:,All attributes of all training examples must have a definite value,All attributes must be discrete,All attributes must be continuous,The same factors must lead to the same conclusion and training examples must be unique,C
"Among the following optimization algorithms, the fastest in terms of convergence speed is",BFGS,Gradient Descent,Newton's Method,Adam,C
Which of the following statements about ALBERT is incorrect?,Cross-layer parameter sharing,Factorization of word embedding parameters,Significant speed improvement in downstream tasks prediction,Removed dropout,D
Which of the following is an application of SVM?,Clustering new articles,Text and hyper-text classification,Image classification,All of the above,D
"In the class domain interface equation method, the method that cannot solve classification problems in linearly inseparable cases is",H-K algorithm based on quadratic criterion,Perceptron algorithm,Potential function method,Pseudoinverse method,B
Which of the following options is a deterministic algorithm,K-Means,PCA,KNN,None of the above,B
"Which of the following algorithms, 1. KNN; 2. Linear regression; 3. Logistic regression, can be constructed using a neural network:",2 and 3,1 and 2,None of the above,"1, 2 and 3",A
The minimum time complexity for training an SVM is O(n²). Which of the following datasets is not suitable for SVM?,Independent of dataset size,Large dataset,Small dataset,Medium-sized dataset,B
"If the random error in a linear regression model has heteroscedasticity, then the ordinary least squares estimator of the parameters is","unbiased, inefficient","unbiased, efficient","biased, inefficient","biased, efficient",A
Which of the following statements about RoBERTa is incorrect,Does not perform the NSP task,Uses a static masking mechanism,Uses more training data,Uses a larger batch size during training,B
"In the case of comparing logistic regression output with targets, which of the following evaluation metrics is not applicable?",Accuracy,Mean Squared Error,AUC-ROC,Logloss,B
"The parameter estimation of language models often uses MLE (Maximum Likelihood Estimation). One problem encountered is that the probability of unseen items is zero, which can lead to poor performance of the language model. To solve this problem, it is necessary to use ( )",Add white noise,Smoothing,Random interpolation,Denoising,B
"Modeling the age distribution of Beijing's population, which distribution is more appropriate?",0-1 distribution,Normal distribution,Poisson distribution,Exponential distribution,B
The cost parameter in SVM indicates:,The balance between misclassification and model complexity,None of the above,The kernel used,The number of cross-validation folds,A
Which of the following correctly describes the generalization error of SVM?,The distance between the hyperplane and the support vectors,The error threshold of SVM,None of the above,SVM's ability to predict unknown data,D
Which of the following statements about BERT is incorrect?,Supports modeling of semantic context,Uses the GELU activation function,The network has a total of 20 layers,Uses transformer,C
"In pattern recognition, which of the following is NOT an advantage of Mahalanobis distance over Euclidean distance?",Scale invariance,Translation invariance,Takes into account the relationships between different features,Considers the distribution of patterns,B
Which distribution is more appropriate for describing the number of times a machine breaks down?,0-1 distribution,Exponential distribution,Normal distribution,Poisson distribution,D
Which of the following is not a characteristic of LSTM itself,LSTM is a variant of RNN,Prevents gradient vanishing,High GPU utilization during training,LSTM has a forget gate,C
Which of the following statements about logistic regression and support vector machines is incorrect?,"Logistic regression is essentially a method that uses samples to perform maximum likelihood estimation of weights, and the posterior probability is proportional to the product of the prior probability and the likelihood function. Logistic regression only maximizes the likelihood function, not the posterior probability, let alone minimizes the posterior probability.",Support vector machines can control the complexity of the model through the regularization coefficient to avoid overfitting.,The goal of support vector machines is to find a hyperplane that separates the training data as much as possible with the largest classification margin; this should belong to structural risk minimization.,"The output of logistic regression is the odds of a sample belonging to the positive class, and probabilities can be calculated.",A
The following is not a major factor affecting the results of clustering algorithms:,Feature selection,Quality of labeled samples,Classification criteria,Pattern similarity measure,B
What criterion does the Gaussian Mixture Model (GMM) use for training?,Minimization of mean squared error,Minimization of empirical risk,Expectation Maximization,None of the other options,C
Which of the following statements is correct:,A machine learning model with high accuracy does not necessarily always indicate that the classifier is good,"We cannot use clustering ""class id"" as a new feature item, and then use supervised learning to learn separately","If the model complexity is increased, the test error rate will always decrease","If the model complexity is increased, the training error rate will always decrease",A
"When replacing synonyms in Chinese using Word2Vec, which of the following statements is incorrect?",Word2Vec results fit the current context,Word2Vec generates synonyms in terms of semantics only,Word2Vec is limited by the quantity and quality of training corpora,Word2Vec is based on probabilistic statistics,B
"Among the following different scenarios, the one where the analytical method is incorrectly applied is","Based on a merchant's operational and service data from the past year, using a clustering algorithm to determine the merchant level of Tmall merchants within their respective main product categories","Based on a merchant's transaction data from recent years, using a clustering algorithm to fit a formula for estimating a user's potential spending amount in the next month",Using an association rule algorithm to analyze whether buyers who purchased car seat cushions should be recommended car floor mats,"Based on a user's recently purchased product information, using a decision tree algorithm to identify whether a Taobao buyer is likely male or female",B
"In data cleaning, which of the following is not a method for handling missing values?",Variable deletion,Estimation,Case deletion,Pairwise deletion,D
Which of the following statements about LDA (Latent Dirichlet Allocation) is incorrect?,LDA is an unsupervised learning technique,LDA can be solved using the EM algorithm,"After selecting a document, the distribution of topics for that document is deterministic","LDA contains three layers: words, topics, and documents",C
"If I use all the features of the dataset and achieve 100% accuracy, but only reach about 70% on the test set, this indicates:",None of the above,Underfitting,Overfitting,The model is great,C
"Assume you are using SVM to learn from data X, and some points in data X contain errors. Now if you use a quadratic kernel function, a polynomial of degree 2, and use the slack variable C as one of the hyperparameters. When you use a large C (C approaches infinity), then:",None of the above,Uncertain,Cannot classify correctly,Can still classify the data correctly,D
Statistical-based word segmentation methods include,Maximum forward matching method,Conditional Random Fields,Minimum segmentation,Maximum backward matching method,B
Suppose a student accidentally duplicated two dimensions of the training data while using a Naive Bayes classification model. Which of the following statements about Naive Bayes is incorrect?,"The model performance, in terms of accuracy compared to the case without duplicate features, will decrease","The model performance, in terms of accuracy compared to the case without duplicate features, will improve","When two features are highly correlated, the conclusion drawn when the two features are identical cannot be used for analysis","If all features are duplicated once, the resulting model predictions will be the same as those from the model without duplication",D
Which of the following statements about word2vec is incorrect?,"Using word vectors, the following equation can be obtained: King - man + woman = Queen",Skip-gram predicts the probability of the current word given the context in a word window,"The assumption of word2vec is the bag-of-words model, where the order of words is not important",Negative Sampling and Hierarchical Softmax are two acceleration algorithms used during word2vec training,B
The following description is correct:,Clustering analysis can be regarded as a form of unsupervised classification.,"In clustering analysis, the greater the similarity within clusters and the greater the differences between clusters, the worse the clustering effect.","SVM is a classifier that seeks the hyperplane with the smallest margin, so it is often referred to as the minimum margin classifier.","In decision trees, as the number of nodes in the tree becomes too large, even though the training error continues to decrease, the test error starts to increase. This indicates the problem of underfitting in the model.",A
"Among the following options, the one with a recognition pattern different from the others is","Mode of transportation judgment: walking, cycling, driving","User age group judgment: teenager, young adult, middle-aged, senior",Mailman sorting letters,Doctor diagnosing disease type for a patient,A
Which of the following statements is incorrect?,The gradient descent method uses the negative gradient at the current position as the search direction.,"The conjugate gradient method only requires first-order derivative information, but its convergence speed is faster than that of the gradient descent method.","Compared with stochastic gradient descent, batch gradient descent has the advantage of being highly efficient for large-scale samples.","Compared with gradient descent, Newton's method has one disadvantage of being more complex to solve, and one advantage of faster convergence speed.",C
"In a Hidden Markov Model, if the observation sequence and the corresponding state sequence that generated the observations are known, which of the following methods can be directly used for parameter estimation?",Forward-backward algorithm,Maximum likelihood estimation,Viterbi algorithm,EM algorithm,B
What is the prior distribution of word distributions under the same topic in LDA (Latent Dirichlet Allocation)?,Normal distribution,Dirichlet distribution,Multinomial distribution,Binomial distribution,C
Which of the following is not a basic assumption of linear regression?,"For all observed values of the explanatory variables, the random error terms have the same variance",The random error term is a random variable with an expected value of 0,The random error term follows a normal distribution,The random error terms are correlated with each other,D
Which of the following is not an SVM kernel function?,Sigmoid kernel function,Radial basis kernel function,Polynomial kernel function,Logistic kernel function,D
Which of the following are unsupervised learning methods,SVM,K-means,KNN,Decision Tree,B
Which of the following methods belongs to discriminative models?,Bayesian network,Naive Bayes,Hidden Markov model,Support Vector Machine,D
"The following cross-validation methods: i. Bootstrap method with replacement; ii. Leave-one-out cross validation; iii. 5-fold cross-validation; iv. 5-fold cross-validation repeated twice. When the number of samples is 1000, which of the following orders of execution time is correct?",ii > iv > iii > i,ii > iii > iv > i,iv > i > ii > iii,i > ii > iii > iv,A
Seq2Seq model decoding methods can include:,Greedy algorithm,Both of the above,Beam Search,None of the above,B
The algorithm for solving the prediction problem in hidden Markov models is,Forward algorithm,Viterbi algorithm,Baum-Welch algorithm,Backward algorithm,B
The correct explanation for the k-means clustering algorithm is:,"Can automatically identify the number of clusters, and does not randomly select initial points as center points for calculation","Cannot automatically identify the number of clusters, and does not randomly select initial points as center points for calculation","Cannot automatically identify the number of clusters, and randomly selects initial points as center points for calculation","Can automatically identify the number of clusters, and randomly selects initial points as center points for calculation",C
"Generally, the k-NN nearest neighbor method works better under which of the following conditions:",Samples are cluster distributed,There are many samples but they are not typical,Samples are chain distributed,There are few samples but they are typical,D
"A prison facial recognition access system is used to identify the identity of individuals seeking entry. This system is designed to recognize four different types of people: correctional officers, thieves, delivery personnel, and others. Which of the following learning methods is most suitable for this type of application requirement?",Multi-class classification problem,Binary classification problem,K-medoids clustering problem,Hierarchical clustering problem,A
"To obtain the same projection as SVD, what should you do in PCA?",Transform the data to zero mean,Not possible,Transform the data to zero mode,Transform the data to zero median,A
"In statistical pattern classification problems, when the prior probabilities are unknown, which of the following can be used?",N-P decision rule,Minimax loss criterion,Minimum loss criterion,Minimum error probability criterion,B
Which of the following methods cannot be directly used for text classification?,Decision Tree,Kmeans,Support Vector Machine,KNN,B
