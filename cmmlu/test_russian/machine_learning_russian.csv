"В задаче бинарной классификации, когда количества положительных и отрицательных примеров в тестовой выборке несбалансированы, какая из следующих схем оценки является относительно нерациональной (предположим, что precision=TP/(TP+FP), recall=TP/(TP+FN)):",F-значение: 2recallprecision/(recall+precision),G-mean: sqrt(precision*recall),Точность: (TP+TN)/all,AUC: площадь под кривой ROC,C
Какой из следующих методов недопустим для решения проблемы переобучения в глубоком обучении,Добавить слой Dropout,Увеличить количество слоев,Расширить данные,Добавить регуляризационный член,B
"Предположим, что у нас есть набор данных, который может быть обучен с 100% точностью при помощи дерева решений глубиной 6. Теперь рассмотрим два пункта и выберем правильный вариант ответа на их основании: 1. При глубине 4 будет высокое смещение (bias) и низкая дисперсия (variance); 2. При глубине 4 будет низкое смещение (bias) и низкая дисперсия (variance). Примечание: все другие гиперпараметры одинаковые, все другие факторы не изменяются.",1 и 2,Только 2,Ни один из них,Только 1,D
Какие из следующих методов нельзя использовать для уменьшения размерности данных,LASSO,Bagging,Метод главных компонент,Кластерный анализ,B
"Различие между L1 и L2 регуляризацией в машинном обучении заключается в том, что","При использовании L1 можно получить разреженные, сглаженные веса","При использовании L2 можно получить разреженные, сглаженные веса","При использовании L1 можно получить разреженные веса, а при использовании L2 – сглаженные веса","При использовании L2 можно получить разреженные веса, а при использовании L1 – сглаженные веса",C
Какое из следующих утверждений о модели скрытой марковской цепи и модели условных случайных полей является неверным?,"Модель скрытой марковской цепи может быть использована для решения задач распознавания именованных сущностей, сегментации текста и определения частей речи",Модель скрытой марковской цепи и модель условных случайных полей обе являются генеративными моделями,Модель скрытой марковской цепи не является вероятностной моделью неориентированных графов,Выбор и оптимизация признаков окажут серьезное влияние на результаты модели скрытой марковской цепи,B
Какой(ие) из следующих гиперпараметров при увеличении могут привести к переобучению данных в методе случайного леса,Скорость обучения,Количество деревьев,Глубина деревьев,Ничего из вышеперечисленного,C
"Какое из следующих утверждений об алгоритме бинарного дерева решений ""итерационное бинарное дерево 3-го поколения"" является неверным?",Итерационное бинарное дерево 3-го поколения является моделью бинарного дерева,"Прирост информации может быть вычислен с использованием энтропии, а не коэффициента Джини",Алгоритм итерационного бинарного дерева 3-го поколения требует дискретизации признаков,В качестве корневого узла дерева выбирается признак с наибольшим приростом информации,A
Какое(ие) из следующих утверждений о перекрестной проверке на K подвыборок является(ются) верным(и),"Если K=N, то это называется скользящее выделение одного образца (leave-one-out), где N – количество образцов в обучающей выборке","По сравнению с меньшими значениями K, большие значения K дают большую уверенность в результатах перекрестной проверки",Все вышеперечисленное,"Увеличение значения K приведет к увеличению времени, необходимого для получения результатов перекрестной проверки",C
"Известно, что имеется m образцов, производится n (n<=m) выборок. Что означает данные boostrap?",Выборка без возвращения n образцов из общего числа N образцов,Выборка без возвращения m характеристик из общего числа M характеристик,Выборка с возвращением n образцов из общего числа N образцов,Выборка с возвращением m характеристик из общего числа M характеристик,C
"Если в качестве меры сходства образов использовать корреляционный коэффициент признаковых векторов, то основными факторами, влияющими на результат алгоритма кластеризации являются",Размерность,Качество известных образцов,Ничего из вышеперечисленного,Правило классификации,D
"В процессе тренировки модели, мы обычно делим данные на",Набор данных для проверки,Набор тестовых данных,Набор обучающих данных,Все вышеперечисленные варианты верны,D
"Вы используете логистическую регрессию с L1-регуляризацией для бинарной классификации, где C – это параметр регуляризации, w1 и w2 – коэффициенты x1 и x2. Какой из следующих вариантов верен, когда вы увеличиваете значение C от 0 до очень большого значения?","Первым обнуляется w1, затем обнуляется и w2",w1 и w2 обнуляются одновременно,"Первым обнуляется w2, затем обнуляется и w1","Даже после того, как C становится очень большим, ни w1, ни w2 не становятся нулевыми",D
Какой из следующих методов нельзя использовать для уменьшения размерности признаков,Deep Learning SparseAutoEncoder,Сингулярное разложение матрицы SVD,Линейный дискриминантный анализ,Метод главных компонент,A
Что определяет теорема Байеса?,Априорная вероятность,Ни один из других вариантов,Условная вероятность,Совместная вероятность,C
В машинном обучении для объяснения обобщающей способности алгоритма часто используется разложение на смещение-дисперсию. Какое из следующих утверждений является неверным?,Дисперсия отражает стабильность предсказаний алгоритма,Смещение отражает точность предсказаний алгоритма,"Обобщающая способность определяется возможностями алгоритма обучения, достаточностью данных и сложностью самой задачи обучения",Дисперсия означает отклонение ожидаемого значения прогноза от истинного значения,D
"Если вы используете алгоритм логистической регрессии для прогнозирования объема продаж компьютеров и обнаруживаете, что при проверке гипотезы на новом тестовом наборе данные прогноза имеют большое отклонение, а также ваша гипотеза показывает плохие результаты на обучающем наборе, какого из следующих шагов следует избегать?",Попробуйте уменьшить параметр регуляризации λ,Попробуйте добавить перекрестные признаки,Увеличьте размер выборки,Попробуйте использовать меньший тестовый набор или признаки,D
"Пусть P(w) обозначает вероятность появления термина w. Предположим, что известно: P(Нанкин) = 0,8; P(мэр) = 0,6; P(цзяндацяо) = 0,4; P(город Нанкин) = 0,3; P(Янцзыцяо) = 0,5. Если предположить, что появление двух соседних слов независимо, то результат разбиения на слова будет следующим:",Нанкин_мэр_цзяндацяо,Город Нанкин_Янцзы_цяо,Мэр города Нанкин_цзяндацяо,Город Нанкин_Янцзыцяо,A
В чем разница между регрессией логистических коэффициентов (logistics regression) и общеизвестным регрессионным анализом?,Регрессия логистических коэффициентов предназначена для предсказания вероятности наступления событий,Регрессию логистических коэффициентов можно использовать для оценки коэффициентов регрессии,Все вышеперечисленное,Регрессию логистических коэффициентов можно использовать для измерения степени соответствия модели,C
Какое из следующих утверждений ошибках типа 1 и типа 2 является неверным,"Ошибка типа 1 возникает, когда гипотеза отвергается, хотя она верна","Ошибка типа 1 обычно называется ложноположительной, а ошибка типа 2 — ложноотрицательной",Все вышеперечисленное,"Ошибка типа 2 обычно называется ложноположительной, а ошибка типа 1 — ложноотрицательной",D
"Основные факторы, влияющие на базовый алгоритм K-средних:",Выбор начальных центров классов,Критерий кластеризации,Порядок ввода образцов,Мера сходства образов,D
Гауссовская смесь моделей (GMM) является какой моделью?,Модель обучения без учителя,Никакой из других вариантов,Полуобученная модель,Модель обучения с учителем,A
"Метод, основанный на грамматических правилах:",Условные случайные поля,Модель максимальной энтропии,Синтаксический и семантический анализ,Модель скрытой марковской цепи максимальной энтропии,B
"Имеются две точки выборки, первая точка - положительный образец с вектором признаков (0,-1); вторая точка - отрицательный образец с вектором признаков (2,3). Уравнение классификационной поверхности линейного SVM-классификатора, построенного на основе этих двух точек:",2x-y=0,x+2y=5,x+2y=3,2x+y=4,C
"Модель скрытой марковской цепи имеет пространство наблюдаемых значений и пространство состояний. Если для декодирования использовать алгоритм Витерби (Viterbi algorithm), то временная сложность составит",O(NK),O(N^2K),Ни один из перечисленных вариантов,O(NK^2),C
"Предположим, что вы используете ядро RBF с очень большим значением γ. Это означает, что:",На модель не влияет расстояние точек до гиперплоскости,Ничего из вышеперечисленного,"Модель строится только на основе точек, близких к гиперплоскости","Модель будет учитывать точки, находящиеся далеко от гиперплоскости",C
"Какое из следующих утверждений о мощности спектра модели ARMA (авторегрессионная скользящая средняя), AR (авторегрессионная модель), MA (модель скользящей средней) является правильным?","Когда нули AR-модели близки к единичной окружности, спектр AR имеет острый пик",MA-модель создается с помощью одного и того же фильтра всеобщего пропускания,"Когда полюсы MA-модели близки к единичной окружности, спектр MA имеет глубокий минимум","Спектр ARMA имеет как острые пики, так и глубокие минимумы",D
"Выбор переменных используется для выбора подмножества наилучших дискриминаторов. Если необходимо учитывать эффективность модели, то при выборе переменных нужно учитывать все следующие аспекты, кроме",Перекрестная проверка (cross-validation),Насколько велика роль переменной в интерпретации модели,"Информация, содержащаяся в признаках",Множество переменных на самом деле имеют одно и то же назначение,B
Какая из следующих моделей временных рядов лучше всего подходит для анализа и прогнозирования волатильности,auto regressive model AR模型,自回归滑动平均模型,滑动平均模型,广义自回归滑动平均模型,D
"При построении линейных моделей мы обращаем внимание на корреляцию между переменными. При поиске коэффициентов корреляции в матрице корреляций, мы обнаружили, что три пары переменных (Var1 и Var2, Var2 и Var3, Var3 и Var1) имеют коэффициенты корреляции -0.98, 0.45, 1.23 соответственно. Какой вывод мы можем сделать?",Все вышеперечисленное,"Поскольку Var1 и Var2 очень сильно коррелируют, мы можем удалить одну из них",Var1 и Var2 очень сильно коррелируют,Коэффициент корреляции 1.23 между Var3 и Var1 невозможен,A
Какие методы могут быть использованы при выборе признаков в машинном обучении?,Все вышеперечисленные,Хи-квадрат,Прирост информации,Ожидаемая перекрестная энтропия,A
"Основное различие между LSTM и GRU заключается в том, что GRU объединяет какие два порога LSTM?",forget gate и input gate,input gate и output gate,forget gate и output gate,output gate и reset gate,A
"Алфавит a, b, c, d, все они независимы друг от друга, с соответствующими вероятностями 1/2, 1/4, 1/8, 1/16. Символ с наименьшим количеством информации - это",d,b,a,c,C
"Предположим, вы используете функцию log-loss в качестве оценочного критерия. Какой из следующих вариантов правильно объясняет log-loss в качестве оценочного критерия?",Все вышеперечисленные,"Чем ниже log-loss, тем лучше модель","Для конкретного наблюдения, если классификатор присвоит очень маленькую вероятность правильной категории, то соответствующее значение log-loss будет очень большим","Если классификатор уверен в неправильной классификации, log-loss серьезно накажет это",A
"Известно, что матрица ковариации набора данных равна P. Ниже приведены неверные утверждения о главных компонентах:",Анализ главных компонент это преобразование Карунена-Лоэва (K-L),После разложения на главные компоненты матрица ковариации становится диагональной,"Оптимальный критерий анализа главных компонент заключается в том, чтобы разложить набор данных по ортогональному базису. При условии выбора одинакового количества компонент, среднеквадратическая ошибка будет минимальной",Главные компоненты получаются путем вычисления собственных значений матрицы ковариации,A
Какое из следующих утверждений об attention-механизме является неверным?,attention-механизм назначает каждому элементу последовательности коэффициент веса,"attention-механизм может использоваться в таких сценариях, как машинное чтение и диалоговые системы",традиционная модель encoder-decoder имеет проблемы с длинными зависимостями,"вариант attention-механизма, multi-head attention-механизм не подходит для параллелизации, так как каждый шаг вычисления зависит от результата предыдущего шага",D
Какой из следующих вариантов не является методом уменьшения переобучения,Сбор дополнительных обучающих данных,"Очистка данных, уменьшение шума",Увеличение количества нейронов в скрытом слое нейронной сети,Упрощение предположений модели,C
"При заданных трех переменных X, Y, Z коэффициенты корреляции Пирсона для (X, Y), (Y, Z) и (X, Z) обозначаются как C1, C2 и C3 соответственно. Теперь все значения X увеличиваются на 2 (т.е. X+2), все значения Y уменьшаются на 2 (т.е. Y-2), а Z остается неизменной. После этого коэффициенты корреляции для пар (X, Y), (Y, Z) и (X, Z) обозначаются как D1, D2 и D3 соответственно. Каково соотношение между D1, D2, D3 и C1, C2, C3?","D1 = C1, D2 < C2, D3 < C3","D1= C1, D2 < C2, D3 > C3","D1 = C1, D2 = C2, D3 = C3","D1 = C1, D2 > C2, D3 > C3",C
"Какое из утверждений, касающихся прироста информации атрибутов, используемых в дереве решений для разделения узлов, является неверным?","Прирост информации имеет тенденцию выбирать атрибуты, имеющие большее количество значений",Прирост информации можно получить с использованием энтропии,Для узлов с меньшей неоднородностью требуется больше информации для различения совокупности,Ничего из вышеперечисленного,C
Какое из следующих утверждений остаточных значений в регрессионном анализе является верным?,Среднее значение остатков всегда меньше нуля,Среднее значение остатков всегда больше нуля,Среднее значение остатков всегда равно нулю,Остатки не имеют такой закономерности,C
Мы создаем модель машинного обучения с 5000 признаками и 1 миллионом примеров данных. Как эффективно справиться с обучением на таких больших данных?,Мы случайным образом выбираем некоторые образцы и обучаемся на этих небольших образцах,Все вышеперечисленные,Мы можем использовать алгоритмы онлайн-обучения,Мы применяем алгоритм PCA для уменьшения размерности и уменьшения количества признаков,B
Какое из перечисленных не является преимуществом модели условных случайных полей (CRF) по сравнению с моделью скрытой марковской цепи (HMM) и моделью максимальной энтропии для скрытых марковских моделей?,Скорость работы,Возможность обработки большего объема контекстуальной информации,Глобальная оптимальность,Гибкость выбора признаков,A
Какой из следующих вариантов не является основным методом китайского разделения слов на основе словаря,Максимизация энтропии,Максимальная вероятность,Максимальное совпадение,Кратчайший путь,A
"Предположим, вы используете SVM для изучения данных X, в которых некоторые точки содержат ошибки. Теперь, если вы используете квадратичное ядро с полиномиальной степенью 2 и параметр регуляризации C как один из гиперпараметров. Если использовать небольшое значение C (C стремится к 0), тогда:",Неопределенно,Ошибочная классификация,Правильная классификация,Ничего из вышеуказанного,B
Какой из следующих методов относится к порождающим моделям?,Conditional Random Field (CRF),Традиционная нейронная сеть,Наивный байесовский классификатор,Линейная регрессия,C
Какой из следующих вариантов наиболее подвержен переобучению в машинном обучении при прочих равных условиях,Увеличение количества обучающих примеров,Удаление разреженных признаков,Использование гауссового ядра/RBF-ядра в алгоритме SVM,Сокращение количества нейронов в скрытом слое нейронной сети,C
"Для алгоритма GradientBoosting tree, правильным является следующее утверждение:","When increasing the minimum number of samples required to split a node, we can resist overfitting","When reducing the number of samples used to train each individual learner, we can reduce bias","When increasing the minimum number of samples required to split a node, it leads to overfitting","When increasing the number of samples used to train each individual learner, we can reduce variance",A
"Предположим, что после обучения SVM вы получаете линейную границу решения, и считаете, что модель недостаточно обучена. Какой из следующих вариантов вы должны рассмотреть при следующей итерации обучения модели?",Уменьшить обучающие данные,Уменьшить признаки,Вычислить больше переменных,Увеличить обучающие данные,C
Почему речевой сигнал можно разделить на окна? Какими характеристиками он обладает?,Случайная монотонность,Другие варианты не подходят,Кратковременная стационарность,Монотонная инвариантность,C
"В отношении k-кратной перекрестной проверки, какой из следующих вариантов верен для k",Выбор большего k приведет к меньшему смещению (потому что обучающий набор данных ближе к общему набору данных),"Чем больше k, тем не обязательно лучше, выбор большого k увеличит время оценки",При выборе k необходимо минимизировать дисперсию между наборами данных,Все вышеперечисленные,D
Какие из следующих характеристик относятся к евклидовому расстоянию,Инвариантность к масштабированию,Инвариантность к вращению,Независимость от размерности,Учитывает распределение образов,B
"Наивный байесовский классификатор является особым байесовским классификатором, переменная признака - X, метка категории - C, одно из его предположений заключается в том, что","Все размерности переменной признака X являются случайными переменными, условно независимыми по категориям",P(X|C) имеет гауссово распределение,Нормальное распределение с математическим ожиданием 0 и среднеквадратичным отклонением sqr(2)/2,Априорные вероятности P(C) всех категорий равны,A
"В n-мерном пространстве, лучший метод обнаружения выбросов (outlier) это",Построить коробчатую диаграмму,Построить диаграмму рассеяния,Построить график вероятности нормального распределения,Расстояние Махаланобиса,D
"Для линейной регрессионной модели, включающей дополнительные переменные, следующее может быть верным:","R-квадрат уменьшается, скорректированный R-квадрат также уменьшается","R-квадрат является постоянной величиной, скорректированный R-квадрат увеличивается",R-квадрат и скорректированный R-квадрат оба увеличиваются,Ни одно из вышеперечисленного,D
"Специалисты по данным могут использовать несколько алгоритмов (моделей) для прогнозирования, а затем объединить результаты этих алгоритмов для получения окончательного прогноза (ансамблевое обучение). Какое из следующих утверждений о методе ансамблевого обучения является правильным?",Отдельные модели имеют высокую корреляцию,Для всех отдельных моделей используется один и тот же алгоритм,Отдельные модели имеют низкую корреляцию,"При использовании ансамблевого обучения применение «усреднения весов» лучше, чем «голосования»",C
"Мы хотим обучить решающее дерево на большом наборе данных, чтобы потратить меньше времени, мы можем",увеличить скорость обучения,уменьшить количество деревьев,увеличить глубину деревьев,уменьшить глубину деревьев,D
"Мы хотим уменьшить число признаков в наборе данных, то есть уменьшить размерность. Выберите подходящий вариант",Все вышеперечисленные варианты,"Мы сначала используем все признаки, чтобы обучить модель и получить результаты на тестовом наборе. Затем мы удаляем один признак и снова обучаем модель, используя перекрестную проверку для оценки результатов на тестовом наборе. Если результат будет лучше, чем раньше, мы можем удалить этот признак",Использовать метод выбора признаков вперед и метод исключения признаков назад,Посмотреть таблицу корреляций и удалить признаки с самой высокой корреляцией,A
Какая из следующих функций активации не может решить проблему затухания градиента,Leaky-Relu,Elu,Sigmoid,Relu,C
Какой из следующих алгоритмов не относится к часто используемым при выборе признаков для классификации текста,Principal component analysis (Метод главных компонент),Mutual information (Взаимная информация),Information gain (Информационный выигрыш),Chi-square statistic (Значение хи-квадрат теста),A
Процесс решения линейного дискриминантного функционала Фишера заключается в проекции M-мерного вектора признаков в ( ) для решения,одномерное пространство,трехмерное пространство,M-1-мерное пространство,двумерное пространство,A
Какой из следующих вариантов указывает на сильную взаимосвязь между X и Y,"Коэффициент корреляции равен 0,9",Ничего из вышеперечисленного,"p-значение нулевой гипотезы о том, что бета-коэффициент равен 0, составляет 0,0001","t-статистика нулевой гипотезы о том, что бета-коэффициент равен 0, равна 30",A
"В алгоритме k-средних, какой из следующих вариантов можно использовать для достижения глобального минимума?",Все вышеперечисленные,Найти оптимальное количество кластеров,Изменить количество итераций,Попробовать запустить алгоритм с различной инициализацией центроидов,A
"В статистических языковых моделях обычно описывают вероятность произвольного предложения в форме вероятности, используя оценку максимального правдоподобия. Для некоторых слов с низкой частотой встречаемости, несмотря на увеличение обучающих данных, частота появления все еще очень мала. Какой из следующих методов может решить эту проблему?",Сглаживание данных,N-граммная модель,Униграммная модель,Униграммный метод разбиения,A
Какое из следующих утверждений неверно?,"При задании n точек данных, если половина из них используется для обучения, а половина — для тестирования, то разница между ошибкой обучения и ошибкой тестирования будет уменьшаться по мере увеличения n","Boosting и bagging — это методы объединения нескольких классификаторов для голосования, оба метода определяют вес каждого отдельного классификатора на основе его точности","SVM обладает робастностью к шуму (например, к образцам шума из других распределений)",В алгоритме AdaBoost все неправильно классифицированные образцы обновляются с различными пропорциями весов,B
"Источник двоичного кода X посылает символы из множества {-1,1}, после передачи через дискретный безынерционный канал, на приемной стороне Y получает символы из множества {-1,1,0}. Вероятности заданы как P(x=-1)=1/4, P(x=1)=3/4, P(y=-1|x=-1)=4/5, P(y=0|x=-1)=1/5, P(y=1|x=1)=3/4, P(y=0|x=1)=1/4. Найдите условную энтропию H(Y|X)",0.5372,0.2375,0.5273,0.3275,B
Какая из следующих технологий лучше для уменьшения размерности набора данных?,Удаление столбцов с большими различиями в данных,Удаление столбцов с большим количеством отсутствующих значений,Удаление столбцов с различными тенденциями данных,Нет правильного ответа,B
Какой из следующих методов не подходит для уменьшения размерности данных в высокоразмерном пространстве,Кластерный анализ,LASSO,Вейвлет-анализ,Спектральное отображение Лапласа,A
В чем разница между логистической регрессией и множественным регрессионным анализом?,Оценка коэффициентов регрессии в логистической регрессии,Логистическая регрессия предсказывает вероятность наступления определенного события,Логистическая регрессия имеет более высокий коэффициент детерминации,Все вышеперечисленное,D
"Самыми известными алгоритмами снижения размерности являются PCA и t-SNE. Применяя эти два алгоритма к данным «X», мы получаем наборы данных «X_projected_PCA» и «X_projected_tSNE». Какое из следующих утверждений о «X_projected_PCA» и «X_projected_tSNE» является правильным?",Оба могут быть интерпретированы в пространстве ближайших соседей,«X_projected_PCA» может быть интерпретирован в пространстве ближайших соседей,Ни один из них не может быть интерпретирован в пространстве ближайших соседей,«X_projected_tSNE» может быть интерпретирован в пространстве ближайших соседей,D
Какое из следующих утверждений о алгоритме Витерби является неверным?,Вероятность перехода в алгоритме Витерби – это вероятность перехода из одного скрытого состояния в другое скрытое состояние,Алгоритм Витерби является жадным алгоритмом,Алгоритм Витерби может применяться для сегментации китайского текста,Алгоритм Витерби позволяет получить глобальное оптимальное решение,B
Следующее ( ) не относится к оптимальным критериям линейного классификатора,Байесовская классификация,Перцептронная функция критерия,Машина опорных векторов,Критерий Фишера,A
"Для линейной регрессии, какие из следующих предположений должны быть верными?","Важно находить выбросы, потому что линейная регрессия чувствительна к выбросам","Линейная регрессия предполагает, что данные не имеют мультиколлинеарности","Для линейной регрессии требуется, чтобы все переменные соответствовали нормальному распределению",Ни одно из вышеперечисленных,D
Ниже перечислены требования к данным для алгоритма построения дерева решений ID3,Все атрибуты в обучающих примерах должны иметь определенное значение,Все атрибуты должны быть дискретными,Все атрибуты должны быть непрерывными,"Одинаковые факторы должны приводить к одинаковым выводам, а обучающие примеры должны быть уникальными",C
Какой из следующих алгоритмов оптимизации является самым быстрым?,BFGS,Метод градиентного спуска,Метод Ньютона,Adam,C
Какое из следующих утверждений об ALBERT неверно?,Параметры общие для разных слоев,Разложение параметров вектора встраивания слов,Значительное увеличение скорости предсказания в задачах прикладного уровня,Удаление dropout,D
Какой из следующих вариантов относится к применению SVM,Кластеризация новых статей,Текстовая и гипертекстовая классификация,Классификация изображений,Все вышеперечисленное,D
"Метод, который не может решать задачи классификации в случае линейной несепарабельности, используя точное или приближенное решение, в методе уравнений границы классов:","Алгоритм H-K, основанный на квадратичном критерии",Алгоритм персептрона,Метод потенциальных функций,Метод псевдообращения,B
Какой из следующих вариантов относится к детерминированным алгоритмам?,K-Means,PCA,KNN,Ни один из вышеперечисленных,B
"Какие из следующих алгоритмов, 1. KNN; 2. Линейная регрессия; 3. Логистическая регрессия могут быть построены с использованием нейронных сетей:",2 и 3,1 и 2,Ни один из вышеперечисленных,"1, 2 и 3",A
"Минимальная временная сложность при обучении SVM составляет O(n2), то есть какой из следующих наборов данных не подходит для использования SVM?",Не связано с размером набора данных,Крупный набор данных,Небольшой набор данных,Набор данных среднего размера,B
"Если случайные ошибки в модели линейной регрессии обладают гетероскедастичностью, то оценка обычным методом наименьших квадратов для параметров является","несмещенной, неэффективной","несмещенной, эффективной","смещенной, неэффективной","смещенной, эффективной",A
Какое из следующих утверждений о RoBERTa является неверным?,Не выполняет задачу NSP,Использует статический механизм маскирования,Использует больше обучающих данных,Использует больший размер пакета (batch size) при обучении,B
Какой из следующих показателей оценки неприменим в случае сравнения выходных данных логистической регрессии с целевыми значениями?,Точность,Среднеквадратичная ошибка,AUC-ROC,Logloss,B
"Для оценки параметров языковой модели часто используется MLE (максимальное правдоподобие). Одной из проблем является то, что вероятность терминов, которые не встречаются, равна 0. Это может привести к тому, что эффективность языковой модели будет низкой. Для решения этой проблемы необходимо использовать ( )",Добавление белого шума,Сглаживание,Стохастическую интерполяцию,Устранение шума,B
Какое распределение целесообразнее использовать для моделирования возрастного распределения населения в городе Пекин?,Бернулли,Нормальное распределение,Распределение Пуассона,Экспоненциальное распределение,B
Параметр стоимости в SVM означает:,Баланс между ошибочной классификацией и сложностью модели,Ничего из вышеперечисленного,Используемое ядро,Количество перекрестных проверок,A
Какое описание ошибки обобщения SVM является правильным?,Расстояние между гиперплоскостью и опорными векторами,Порог ошибки SVM,Ничего из вышеперечисленного,Способность SVM предсказывать неизвестные данные,D
Какое из следующих утверждений о BERT является неверным?,Поддерживает моделирование семантического контекста,Использует функцию активации GELU,В сети всего 20 слоев,Использует transformer,C
"В распознавании образов, что не относится к преимуществам расстояния Махаланобиса по сравнению с евклидовым расстоянием?",Инвариантность масштаба,Инвариантность переноса,Учитывает связь между различными характеристиками,Учитывает распределение образов,B
Какое распределение целесообразнее использовать для описания количества отказов машины?,Биномиальное распределение,Экспоненциальное распределение,Нормальное распределение,Распределение Пуассона,D
Какое из следующих утверждений не является особенностью LSTM,LSTM является разновидностью RNN,Предотвращает затухание градиента,Использование GPU во время обучения относительно высокое,В LSTM есть gate забывания,C
Какое из следующих утверждений о логистической регрессии и методе опорных векторов неверно?,"По своей природе логистическая регрессия представляет собой метод максимального правдоподобия для оценки весов на основе образцов, а апостериорная вероятность пропорциональна произведению априорной вероятности и функции правдоподобия. Логистическая регрессия максимизирует только функцию правдоподобия, но не апостериорную вероятность, и тем более не минимизирует апостериорную вероятность","Сложность модели метода опорных векторов можно контролировать с помощью коэффициента регуляризации, чтобы избежать переобучения.","Целью метода опорных векторов является поиск гиперплоскости, которая максимально разделяет обучающие данные и обеспечивает наибольший зазор между классами. Это соответствует принципу минимизации структурного риска","Выходное значение логистической регрессии представляет шансы принадлежности образца к положительному классу, на его основе можно рассчитать вероятность",A
"Следующее не относится к основным факторам, влияющим на результат алгоритма кластеризации",Выбор признаков,Качество выборки с известными классами,Правило классификации,Мера сходства образов,B
Какой критерий используется при обучении гауссовой смесевой модели (GMM)?,Минимизация среднеквадратичной ошибки,Минимизация эмпирического риска,Максимизация ожидания,Ни один из перечисленных вариантов,C
Какое из следующих утверждений верно?,"Если модель машинного обучения имеет высокую точность, это не всегда означает, что классификатор хорош","Мы не можем использовать кластерный «идентификатор класса» в качестве нового признака, а затем использовать обучение с учителем для отдельного изучения","Если увеличить сложность модели, то ошибка тестирования модели всегда будет снижаться","Если увеличить сложность модели, то ошибка обучения модели всегда будет снижаться",A
При замене синонимов в китайском языке часто используется Word2Vec. Какое из следующих утверждений является неверным?,Результат Word2Vec соответствует текущей языковой среде,"Все синонимы, полученные с помощью Word2Vec, являются семантическими",Word2Vec ограничен количеством и качеством обучающих данных,Word2Vec основан на вероятностной статистике,B
Какой из следующих вариантов использования аналитических методов в разных сценариях является неправильным?,"Определение уровней продавцов на Tmall по категориям товаров, которыми они торгуют, с использованием алгоритма кластеризации на основе данных о деятельности и обслуживании продавца за последний год","Использование алгоритма кластеризации для построения формулы, прогнозирующей сумму потребительских расходов пользователя в следующем месяце, на основе данных о покупках продавца за последние несколько лет","Анализ с помощью алгоритма правил ассоциации, чтобы определить, следует ли рекомендовать покупателям, приобретшим автомобильные сиденья, купить также автомобильные коврики","Идентификация пола покупателя с использованием алгоритма дерева решений на основе информации о товарах, недавно приобретенных пользователем",B
Какой из следующих вариантов не является методом обработки пропущенных значений при очистке данных?,Удаление переменных,Оценка,Удаление всей строки,Попарное удаление,D
Какое из следующих утверждений о LDA (Latent Dirichlet Allocation) является ложным?,LDA является техникой обучения без учителя,Параметры LDA могут быть найдены с помощью идеи EM-алгоритма,После выбора документа распределение тем для этого документа является фиксированным,"LDA включает три уровня структуры: слова, темы и документы",C
"Если я использую все признаки набора данных и достигаю точности 100%, но на тестовом наборе данных получаю всего около 70%, это говорит о том, что:",Не одно из вышеперечисленного,Недообучение (Underfitting),Переобучение (Overfitting),Модель отличная,C
"Предположим, вы обучаете данные X, используя SVM. В данных X некоторые точки содержат ошибки. Теперь, если вы используете квадратичную ядровую функцию, порядок полинома равен 2, также используется переменная ослабления C в качестве гиперпараметра. Когда вы используете большее значение C (C стремится к бесконечности), тогда:",выше перечисленное неверно,неопределенно,нельзя классифицировать правильно,все еще можно правильно классифицировать данные,D
Статистический метод сегментации – это,Метод прямого максимального совпадения,Условные случайные поля,Минимальное разделение,Метод обратного максимального совпадения,B
"Предположим, что студент, применяя модель классификации наивного байесовского классификатора, случайно дублирует две размерности обучающих данных. Тогда какое из следующих утверждений о наивном Байесе является неверным?","Качество модели по сравнению со случаем, когда нет повторяющихся признаков, снизится","Качество модели по сравнению со случаем, когда нет повторяющихся признаков, повысится","Когда две колонки признаков сильно коррелируют, нельзя использовать выводы, полученные в случае, когда две колонки признаков совпадают, для анализа задачи","Если все признаки будут продублированы, результаты предсказания полученной модели будут такими же, как и в случае, когда не было дублирования",D
Какое из следующих утверждений о word2vec является неверным?,"Используя векторы слов, можно получить следующее равенство: King - man + woman = Queen",Skip-gram предсказывает вероятность текущего слова на основе контекста заданного окном слов,"Предположение word2vec заключается в использовании модели мешка слов, при этом порядок слов не важен",При обучении word2vec используются два алгоритма ускорения: отрицательная выборка (Negative Sample) и иерархический Softmax (Hierarchical Softmax),B
Какое из следующих утверждений верно?,Кластерный анализ можно рассматривать как безнадзорную классификацию.,"В кластерном анализе, чем больше сходства внутри кластеров и чем больше различий между кластерами, тем хуже результат кластеризации.","SVM – это классификатор, который ищет гиперплоскость с минимальным полем, поэтому его также часто называют классификатором минимального поля.","В деревьях решений, когда количество узлов становится слишком большим, ошибка проверки начинает увеличиваться, даже если ошибка обучения все еще уменьшается; это явление называется недообучением модели.",A
Какой из следующих вариантов отличается от других по способу распознавания,"Определение способа передвижения: пешком, на велосипеде, на машине","Определение возрастного распределения пользователей: подросток, молодой человек, взрослый, пожилой человек",Сортировка писем почтальоном,Диагностирование типа заболевания врачом,A
Какое из следующих утверждений неверно?,Метод градиентного спуска использует в качестве направления поиска отрицательный градиент текущей позиции,"Метод сопряженных градиентов использует информацию только о первых производных, однако скорость сходимости выше, чем у метода градиентного спуска","По сравнению с стохастическим градиентным спуском, полный (batch) градиентный спуск имеет преимущество высокой эффективности при большом объеме выборки","По сравнению с градиентным спуском, метод Ньютона имеет недостаток в виде сложности решения, а также преимущество – увеличенную скорость сходимости",C
"В скрытой марковской модели, если последовательность наблюдений и последовательность состояний, которая порождает последовательность наблюдений, известны заранее, то каким из следующих методов можно непосредственно провести оценку параметров?","Алгоритм ""вперед-назад""",Метод максимального правдоподобия,Алгоритм Витерби,EM-алгоритм,B
Какое априорное распределение слов в теме в LDA (Latent Dirichlet allocation)?,Нормальное распределение,Распределение Дирихле,Мультиномиальное распределение,Биномиальное распределение,C
Какое из следующих утверждений не входит в основные предположения линейной регрессии,Для всех значений объясняющей переменной случайный ошибочный член имеет одинаковую дисперсию,Случайный ошибочный член представляет собой случайную переменную с нулевым математическим ожиданием,Случайный ошибочный член подчиняется нормальному распределению,Случайные ошибочные члены коррелируют друг с другом,D
Какой из следующих вариантов не является ядром машины опорных векторов (SVM),Сигмоидальное ядро,Радиальное базисное ядро,Полиномиальное ядро,Логистическое ядро,D
Какие из перечисленных методов являются методами обучения без учителя?,SVM,K-средних,KNN,Дерево решений,B
Какой из следующих методов относится к дискриминативным моделям?,Байесовская сеть,Наивный байесовский классификатор,Скрытая модель Маркова,Машина опорных векторов,D
"Какой из следующих методов перекрестной проверки: i. метод бутстрепа с возвратом; ii. перекрестная проверка с одним тестовым примером; iii. 5-кратная перекрестная проверка; iv. 5-кратная перекрестная проверка, повторенная дважды. Какая последовательность времени выполнения верна, когда образец равен 1000?",ii > iv > iii > i,ii > iii > iv > i,iv > i > ii > iii,i > ii > iii > iv,A
"Методы, которые можно использовать при декодировании модели Seq2Seq",Жадный алгоритм,Оба варианта допустимы,Поиск с возвратом (Beam Search),Оба варианта недопустимы,B
Алгоритм решения задачи прогнозирования в скрытой марковской модели это,прямой алгоритм,алгоритм Витерби,алгоритм Баума-Велша,обратный алгоритм,B
Какое из следующих утверждений о алгоритме кластеризации k-средних является правильным?,"Может автоматически определять количество классов, не выбирает начальные точки случайным образом в качестве центральных точек","Не может автоматически определять количество классов, не выбирает начальные точки случайным образом в качестве центральных точек","Не может автоматически определять количество классов, выбирает начальные точки случайным образом в качестве центральных точек","Может автоматически определять количество классов, выбирает начальные точки случайным образом в качестве центральных точек",C
"В общем, метод k-ближайших соседей работает лучше в случае:",образцы распределены группами,"образцов много, но они нетипичны",образцы распределены цепочками,"образцов мало, но они типичны",D
"Система контроля доступа тюремного учреждения, основанная на распознавании лиц, используется для определения личности людей, собирающихся войти. Система может распознавать 4 разных типа людей: тюремных надзирателей, воров, официантов и других. Какой из следующих методов обучения лучше всего подходит для данного требования?",Многоклассовая классификация,Бинарная классификация,Задача кластеризации методом k-средних,Иерархическая кластеризация,A
"Как вам следует выполнить преобразование данных с помощью PCA, чтобы получить такой же результат проекции, как в SVD?","Преобразовать данные так, чтобы их среднее значение равнялось нулю",Это невозможно,"Преобразовать данные так, чтобы их мода равнялась нулю","Преобразовать данные так, чтобы их медиана равнялась нулю",A
"В задачах статистической классификации образов, когда априорные вероятности неизвестны, можно использовать",N-P решение,Минимаксный критерий потерь,Критерий минимальных потерь,Критерий минимальной вероятности ошибочной классификации,B
Какой из следующих методов нельзя напрямую использовать для классификации текста,Decision Tree,Kmeans,Support Vector Machine,KNN,B
