import csv
import argparse
import os
import re
import time
import openai
from openai import OpenAI
from fractions import Fraction
from sympy import sympify, E
from sympy.core.sympify import SympifyError
from volcenginesdkarkruntime import Ark

doubao_client = Ark(api_key="196b33be-8abb-4af3-9fba-6e266b2dd942")
deepseek_client = OpenAI(api_key="sk-09da13b2c97948628523d042d6a02f06", base_url="https://api.deepseek.com")
kimi_client = OpenAI(api_key="sk-ODuizMlUC22phanBhvYz6dBjx2yrz7vhKhcjKnoIrYssThQo", base_url="https://api.moonshot.cn/v1")
qwen_client = OpenAI(api_key="sk-341becd932d743f2a750495a0f9f3ede", base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")

    
def call_doubao_api(question, temperature=0):
    try:
        response = doubao_client.chat.completions.create(
            model="doubao-1.5-pro-32k-250115",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question},
            ],            
            temperature=temperature,
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨ è±†åŒ… API æ—¶å‡ºé”™: {e}")
        return "âŒ"
    
def call_deepseek_api(question, temperature=0):
    try:
        response = doubao_client.chat.completions.create(
            model="deepseek-v3-250324",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question},
            ],
            temperature=temperature,
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨ DeepSeek API æ—¶å‡ºé”™: {e}")
        return "âŒ"

def call_gpt_api(question, temperature=0):
    os.environ["HTTP_PROXY"] = "http://localhost:7890"
    os.environ["HTTPS_PROXY"] = "http://localhost:7890"
    try:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        response = openai.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question},
            ],
            temperature=temperature,
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨ gpt API æ—¶å‡ºé”™: {e}")
        return "âŒ" 
    
def call_kimi_api(question, temperature=0):
    try:
        response = kimi_client.chat.completions.create(
            model="moonshot-v1-8k",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question},
            ],
            temperature=temperature,
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨ Kimi API æ—¶å‡ºé”™: {e}")
        return "âŒ"
    
def   call_qwen_api(question, temperature=0):
    try:
        response = qwen_client.chat.completions.create(
            model="qwen-plus", 
            messages=[
                {'role': 'system', 'content': 'You are a helpful assistant.'},
                {'role': 'user', 'content': question},
            ],
            temperature=temperature,
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨ Qwen API æ—¶å‡ºé”™: {e}")
        return "âŒ"
    
def get_output_filename(input_name, language):
    # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶ä¸»å
    base = os.path.splitext(os.path.basename(input_name))[0]
    # è¯­è¨€å…¨éƒ¨å°å†™ï¼Œç©ºæ ¼æ¢æˆä¸‹åˆ’çº¿
    lang = language.strip().replace(" ", "_").lower()
    return f"{base}_{lang}.csv"
    
def translate(args):
    output_path = os.path.join(args.out_csv, get_output_filename(args.input, args.language))
    total_count = 0
    success_count = 0
    start_time = time.time()

    # è¯»å– original æ–‡ä»¶å†…å®¹å¹¶ç¼“å­˜åˆ°åˆ—è¡¨ä¸­
    with open(args.original, 'r', encoding='utf-8') as orifile:
        ori_reader = csv.reader(orifile)
        ori_rows = [row for row in ori_reader if row]  # å»é™¤ç©ºè¡Œ

    # è¯»å–è¾“å…¥æ–‡ä»¶å¹¶ç¿»è¯‘
    with open(args.input, 'r', encoding='utf-8') as infile, \
         open(output_path, 'w', newline='', encoding='utf-8') as outfile:
        
        reader = csv.reader(infile)
        writer = csv.writer(outfile)
        
        for row in reader:
            if not row:
                continue
            total_count += 1
            question_text = row[0]          # æ‹¼æ¥é¢˜ç›®
            answer_text = row[1] if len(row) > 1 else ""
            source_info = row[2] if len(row) > 2 else ""  # å½¢å¦‚ "2â†’3" çš„æ¥æºä¿¡æ¯

            # ä» "2â†’3" æå–é¢˜å·
            match = re.match(r"(\d+)\s*â†’\s*(\d+)", source_info)
            if match:
                q1_id, q2_id = int(match.group(1)), int(match.group(2))
            else:
                print(f"âš ï¸ æ— æ³•ä» '{source_info}' æå–é¢˜å·ï¼Œè·³è¿‡è¯¥è¡Œã€‚")
                continue

            # è·å–åŸæ–‡ä¸­å¯¹åº”é¢˜ç›®çš„å†…å®¹
            try:
                q1_original = ori_rows[q1_id - 1][0]  # æ–‡ä»¶ä¸­ç¬¬ n é¢˜ï¼Œå¯¹åº”ç´¢å¼• n-1
                q2_original = ori_rows[q2_id - 1][0]
            except IndexError:
                print(f"âš ï¸ é¢˜å· {q1_id} æˆ– {q2_id} è¶…å‡º original æ–‡ä»¶èŒƒå›´ï¼Œè·³è¿‡ã€‚")
                continue

            # æ„é€ æç¤ºè¯ï¼ˆPromptï¼‰
            prompt = (
                f"{question_text}\n"
                f"æŠŠä¸Šé¢çš„å†…å®¹ç¿»è¯‘ä¸º {args.language}ï¼Œä¿ç•™ä¸‹é¢çš„ç¿»è¯‘ä¸­ç¿»è¯‘å¥½çš„éƒ¨åˆ†ï¼Œæœ€åå¾—åˆ°ä¸Šé¢è¿™æ®µè¯çš„å®Œæ•´{args.language}ç¿»è¯‘ï¼Œä¸è¦å¿˜äº†ç¿»è¯‘â€œLet the answer be $k$â€ï¼š\n"
                f"{q1_original}"
                f"{q2_original}\n"
                f"åªç¿»è¯‘ï¼Œä¸è§£é¢˜ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚"
            )

            # è°ƒç”¨æ¨¡å‹
            if args.model == "qwen":
                print(f"ğŸ›° è°ƒç”¨ Qwen æ¨¡å‹ç¿»è¯‘ç¬¬ {total_count} è¡Œï¼š...")
                translation = call_qwen_api(prompt, temperature=args.temperature)
            elif args.model == "deepseek":
                print(f"ğŸ›° è°ƒç”¨ DeepSeek æ¨¡å‹ç¿»è¯‘ç¬¬ {total_count} è¡Œï¼š...")
                translation = call_deepseek_api(prompt, temperature=args.temperature)
            elif args.model == "kimi":
                print(f"ğŸ›° è°ƒç”¨ Kimi æ¨¡å‹ç¿»è¯‘ç¬¬ {total_count} è¡Œï¼š...")
                translation = call_kimi_api(prompt, temperature=args.temperature)
            elif args.model == "gpt":
                print(f"ğŸ›° è°ƒç”¨ GPT æ¨¡å‹ç¿»è¯‘ç¬¬ {total_count} è¡Œï¼š...")
                translation = call_gpt_api(prompt, temperature=args.temperature)
            elif args.model == "doubao":    
                print(f"ğŸ›° è°ƒç”¨ è±†åŒ… æ¨¡å‹ç¿»è¯‘ç¬¬ {total_count} è¡Œï¼š...")
                translation = call_doubao_api(prompt, temperature=args.temperature)
            else:
                print(f"âŒ æœªçŸ¥æ¨¡å‹: {args.model}")
                translation = "âŒ"

            print(f"==== ç¬¬ {total_count} è¡Œç¿»è¯‘ç»“æœ ====\n{translation}\n")
            success_count += 1

            # å†™å…¥è¾“å‡ºæ–‡ä»¶
            writer.writerow([translation, answer_text, source_info])

    end_time = time.time()
    total_time = end_time - start_time
    avg_time = total_time / total_count if total_count > 0 else 0

    print(f"âœ… ç¿»è¯‘ç»“æœä¿å­˜åˆ°: {output_path}")
    print(f"æ€»è¡Œæ•°: {total_count}ï¼ŒæˆåŠŸç¿»è¯‘: {success_count}ï¼Œå¹³å‡è€—æ—¶: {avg_time:.2f} ç§’/è¡Œ")
    

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ‰¹é‡è°ƒç”¨ DeepSeek ç¿»è¯‘")
    parser.add_argument('--input', required=True, help="è¾“å…¥ CSV æ–‡ä»¶å")
    parser.add_argument('--original', required=True, help="å¯¹åº”çš„MESæ–‡ä»¶")
    parser.add_argument('--out_csv', default='./csv', help="è¾“å‡ºCSV æ–‡ä»¶æ‰€åœ¨æ–‡ä»¶å¤¹")
    parser.add_argument('--language', required=True, help="ç›®æ ‡è¯­è¨€ï¼Œå¦‚ French, German, Japanese ç­‰")
    parser.add_argument('--temperature', type=float, default=0.2, help="API å›ç­”å¤šæ ·æ€§ï¼Œé»˜è®¤ 0.2")
    parser.add_argument('--model', type=str, default="deepseek", help="ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¦‚gptã€deepseekã€kimiã€qwen")
    args = parser.parse_args()

    translate(args)